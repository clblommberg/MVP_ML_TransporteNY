{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos\n",
    "## Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import pandas as pd\n",
    "from datetime import date, time\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os import listdir\n",
    "# from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ruta al directorio que contiene los archivos Parquet\n",
    "directorio = \"..\\\\datasets\\\\raw\\\\\"\n",
    "\n",
    "# Obtener la lista de archivos en el directorio\n",
    "archivos_parquet = [f for f in os.listdir(directorio) if os.path.isfile(os.path.join(directorio, f)) and f.endswith('.parquet')]\n",
    "\n",
    "# Crear un diccionario para almacenar los DataFrames de Polars\n",
    "diccionario_dataframes = {}\n",
    "\n",
    "# Iterar sobre los archivos Parquet\n",
    "for archivo in archivos_parquet:\n",
    "    # Verificar si el archivo contiene \"yellow\", \".parquet\" y \"2023\" en su nombre\n",
    "    if 'yellow' in archivo and '.parquet' in archivo and '2023' in archivo:\n",
    "        # Obtener el mes del archivo\n",
    "        mes = archivo.split('_')[2].split('-')[1].split('.')[0]  # Extraer el mes del nombre del archivo\n",
    "        \n",
    "        # Construir la ruta completa al archivo\n",
    "        ruta_archivo = os.path.join(directorio, archivo)\n",
    "        \n",
    "        # Leer el archivo Parquet en un DataFrame de Polars\n",
    "        df = pl.read_parquet(ruta_archivo)\n",
    "        \n",
    "        # Agregar el DataFrame al diccionario utilizando el nombre del archivo como clave\n",
    "        diccionario_dataframes[mes] = df\n",
    "\n",
    "# Ahora el diccionario 'diccionario_dataframes' contiene un DataFrame por mes para el año 2023\n",
    "# de los archivos Parquet que contienen \"yellow\" en su nombre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del DataFrame '01':\n",
      "Cantidad de registros : 3066766 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '02':\n",
      "Cantidad de registros : 2913955 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '03':\n",
      "Cantidad de registros : 3403766 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '04':\n",
      "Cantidad de registros : 3288250 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '05':\n",
      "Cantidad de registros : 3513649 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '06':\n",
      "Cantidad de registros : 3307234 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '07':\n",
      "Cantidad de registros : 2907108 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '08':\n",
      "Cantidad de registros : 2824209 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '09':\n",
      "Cantidad de registros : 2846722 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '10':\n",
      "Cantidad de registros : 3522285 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '11':\n",
      "Cantidad de registros : 3339715 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n",
      "Información del DataFrame '12':\n",
      "Cantidad de registros : 3376567 Cantidad de las Columnas : 19\n",
      "Schema\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre el diccionario de dataframes\n",
    "for nombre, df in diccionario_dataframes.items():\n",
    "    print(f\"Información del DataFrame '{nombre}':\")\n",
    "    print(\"Cantidad de registros :\", len(df), \"Cantidad de las Columnas :\", len(df.columns))\n",
    "    print(\"Schema\")\n",
    "    #print(df.schema)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('VendorID', Int32), ('tpep_pickup_datetime', Datetime(time_unit='ns', time_zone=None)), ('tpep_dropoff_datetime', Datetime(time_unit='ns', time_zone=None)), ('passenger_count', Int64), ('trip_distance', Float64), ('RatecodeID', Int64), ('store_and_fwd_flag', String), ('PULocationID', Int32), ('DOLocationID', Int32), ('payment_type', Int64), ('fare_amount', Float64), ('extra', Float64), ('mta_tax', Float64), ('tip_amount', Float64), ('tolls_amount', Float64), ('improvement_surcharge', Float64), ('total_amount', Float64), ('congestion_surcharge', Float64), ('Airport_fee', Float64)])\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que diccionario_dataframes es tu diccionario que contiene los DataFrames\n",
    "# Reemplaza diccionario_dataframes con el nombre de tu diccionario\n",
    "\n",
    "# Tomar el primer DataFrame del diccionario\n",
    "primer_df = next(iter(diccionario_dataframes.values()))\n",
    "\n",
    "# Definir un nuevo esquema con los tipos de datos y nombres de columna deseados\n",
    "nuevo_esquema = {\n",
    "    \"VendorID\": pl.Int32,\n",
    "    \"tpep_pickup_datetime\": pl.Datetime(time_unit='ns', time_zone=None),\n",
    "    \"tpep_dropoff_datetime\": pl.Datetime(time_unit='ns', time_zone=None),\n",
    "    \"passenger_count\": pl.Int64,\n",
    "    \"trip_distance\": pl.Float64,\n",
    "    \"RatecodeID\": pl.Int64,\n",
    "    \"store_and_fwd_flag\": pl.String,\n",
    "    \"PULocationID\": pl.Int32,\n",
    "    \"DOLocationID\": pl.Int32,\n",
    "    \"payment_type\": pl.Int64,\n",
    "    \"fare_amount\": pl.Float64,\n",
    "    \"extra\": pl.Float64,\n",
    "    \"mta_tax\": pl.Float64,\n",
    "    \"tip_amount\": pl.Float64,\n",
    "    \"tolls_amount\": pl.Float64,\n",
    "    \"improvement_surcharge\": pl.Float64,\n",
    "    \"total_amount\": pl.Float64,\n",
    "    \"congestion_surcharge\": pl.Float64,\n",
    "    \"airport_fee\": pl.Float64,  # He cambiado el nombre de la columna a \"airport_fee\"\n",
    "}\n",
    "\n",
    "# Renombrar las columnas y cambiar los tipos de datos del DataFrame\n",
    "df = primer_df.select([\n",
    "    pl.col(col).cast(dtype).alias(col) for col, dtype in nuevo_esquema.items()\n",
    "])\n",
    "\n",
    "# Cambiar el nombre de la columna \"airport_fee\" a \"Airport_fee\"\n",
    "df = df.with_columns(primer_df['airport_fee'].alias('Airport_fee'))\n",
    "df = df.drop('airport_fee')\n",
    "# Reemplazar el DataFrame original en el diccionario con el DataFrame modificado\n",
    "nombre_clave = next(iter(diccionario_dataframes))  # Obtener la clave del primer DataFrame\n",
    "diccionario_dataframes[nombre_clave] = df\n",
    "\n",
    "# Verificar el resultado\n",
    "print(diccionario_dataframes[nombre_clave].schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre el diccionario de dataframes\n",
    "# for nombre, df in diccionario_dataframes.items():\n",
    "#     print(f\"Información del DataFrame '{nombre}':\")\n",
    "#     print(\"Cantidad de registros :\", len(df), \"Cantidad de las Columnas :\", len(df.columns))\n",
    "#     print(\"Schema\")\n",
    "#     print(df.schema)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora que todos los DataFrames tienen las mismas columnas, puedes proceder a concatenarlos.\n",
    "dataframes = list(diccionario_dataframes.values())\n",
    "\n",
    "# Concatenar verticalmente todos los DataFrames\n",
    "df_concatenado = pl.concat(dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38310226, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('VendorID', Int32),\n",
       "             ('tpep_pickup_datetime',\n",
       "              Datetime(time_unit='ns', time_zone=None)),\n",
       "             ('tpep_dropoff_datetime',\n",
       "              Datetime(time_unit='ns', time_zone=None)),\n",
       "             ('passenger_count', Int64),\n",
       "             ('trip_distance', Float64),\n",
       "             ('RatecodeID', Int64),\n",
       "             ('store_and_fwd_flag', String),\n",
       "             ('PULocationID', Int32),\n",
       "             ('DOLocationID', Int32),\n",
       "             ('payment_type', Int64),\n",
       "             ('fare_amount', Float64),\n",
       "             ('extra', Float64),\n",
       "             ('mta_tax', Float64),\n",
       "             ('tip_amount', Float64),\n",
       "             ('tolls_amount', Float64),\n",
       "             ('improvement_surcharge', Float64),\n",
       "             ('total_amount', Float64),\n",
       "             ('congestion_surcharge', Float64),\n",
       "             ('Airport_fee', Float64)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenado.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>Airport_fee</th></tr><tr><td>i32</td><td>datetime[ns]</td><td>datetime[ns]</td><td>i64</td><td>f64</td><td>i64</td><td>str</td><td>i32</td><td>i32</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2</td><td>2023-01-01 00:32:10</td><td>2023-01-01 00:40:36</td><td>1</td><td>0.97</td><td>1</td><td>&quot;N&quot;</td><td>161</td><td>141</td><td>2</td><td>9.3</td><td>1.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>14.3</td><td>2.5</td><td>0.0</td></tr><tr><td>2</td><td>2023-01-01 00:55:08</td><td>2023-01-01 01:01:27</td><td>1</td><td>1.1</td><td>1</td><td>&quot;N&quot;</td><td>43</td><td>237</td><td>1</td><td>7.9</td><td>1.0</td><td>0.5</td><td>4.0</td><td>0.0</td><td>1.0</td><td>16.9</td><td>2.5</td><td>0.0</td></tr><tr><td>2</td><td>2023-01-01 00:25:04</td><td>2023-01-01 00:37:49</td><td>1</td><td>2.51</td><td>1</td><td>&quot;N&quot;</td><td>48</td><td>238</td><td>1</td><td>14.9</td><td>1.0</td><td>0.5</td><td>15.0</td><td>0.0</td><td>1.0</td><td>34.9</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2023-01-01 00:03:48</td><td>2023-01-01 00:13:25</td><td>0</td><td>1.9</td><td>1</td><td>&quot;N&quot;</td><td>138</td><td>7</td><td>1</td><td>12.1</td><td>7.25</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>20.85</td><td>0.0</td><td>1.25</td></tr><tr><td>2</td><td>2023-01-01 00:10:29</td><td>2023-01-01 00:21:19</td><td>1</td><td>1.43</td><td>1</td><td>&quot;N&quot;</td><td>107</td><td>79</td><td>1</td><td>11.4</td><td>1.0</td><td>0.5</td><td>3.28</td><td>0.0</td><td>1.0</td><td>19.68</td><td>2.5</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 19)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ VendorID ┆ tpep_pick ┆ tpep_drop ┆ passenger ┆ … ┆ improveme ┆ total_amo ┆ congestio ┆ Airport_f │\n",
       "│ ---      ┆ up_dateti ┆ off_datet ┆ _count    ┆   ┆ nt_surcha ┆ unt       ┆ n_surchar ┆ ee        │\n",
       "│ i32      ┆ me        ┆ ime       ┆ ---       ┆   ┆ rge       ┆ ---       ┆ ge        ┆ ---       │\n",
       "│          ┆ ---       ┆ ---       ┆ i64       ┆   ┆ ---       ┆ f64       ┆ ---       ┆ f64       │\n",
       "│          ┆ datetime[ ┆ datetime[ ┆           ┆   ┆ f64       ┆           ┆ f64       ┆           │\n",
       "│          ┆ ns]       ┆ ns]       ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 2        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 1         ┆ … ┆ 1.0       ┆ 14.3      ┆ 2.5       ┆ 0.0       │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:32:10  ┆ 00:40:36  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 1         ┆ … ┆ 1.0       ┆ 16.9      ┆ 2.5       ┆ 0.0       │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:55:08  ┆ 01:01:27  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 1         ┆ … ┆ 1.0       ┆ 34.9      ┆ 2.5       ┆ 0.0       │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:25:04  ┆ 00:37:49  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 1        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 0         ┆ … ┆ 1.0       ┆ 20.85     ┆ 0.0       ┆ 1.25      │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:03:48  ┆ 00:13:25  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 1         ┆ … ┆ 1.0       ┆ 19.68     ┆ 2.5       ┆ 0.0       │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:10:29  ┆ 00:21:19  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tpep_pickup_datetime|tpep_dropoff_datetime / fechas  a segundos y fechas unicamente\n",
    "# trip_distance tratar las filas con distanca cero \n",
    "# RatecodeID| 6 datos adminitidos  (99) valores faltantes\n",
    "# payment_type 1 y 2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nyc = df_concatenado.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37000870, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nyc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Preprocessing\n",
    "### Preprocesamiento Variables `Temporales` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>Airport_fee</th></tr><tr><td>i32</td><td>datetime[ns]</td><td>datetime[ns]</td><td>i64</td><td>f64</td><td>i64</td><td>str</td><td>i32</td><td>i32</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2</td><td>2023-01-01 00:32:10</td><td>2023-01-01 00:40:36</td><td>1</td><td>0.97</td><td>1</td><td>&quot;N&quot;</td><td>161</td><td>141</td><td>2</td><td>9.3</td><td>1.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>14.3</td><td>2.5</td><td>0.0</td></tr><tr><td>2</td><td>2023-01-01 00:55:08</td><td>2023-01-01 01:01:27</td><td>1</td><td>1.1</td><td>1</td><td>&quot;N&quot;</td><td>43</td><td>237</td><td>1</td><td>7.9</td><td>1.0</td><td>0.5</td><td>4.0</td><td>0.0</td><td>1.0</td><td>16.9</td><td>2.5</td><td>0.0</td></tr><tr><td>2</td><td>2023-01-01 00:25:04</td><td>2023-01-01 00:37:49</td><td>1</td><td>2.51</td><td>1</td><td>&quot;N&quot;</td><td>48</td><td>238</td><td>1</td><td>14.9</td><td>1.0</td><td>0.5</td><td>15.0</td><td>0.0</td><td>1.0</td><td>34.9</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2023-01-01 00:03:48</td><td>2023-01-01 00:13:25</td><td>0</td><td>1.9</td><td>1</td><td>&quot;N&quot;</td><td>138</td><td>7</td><td>1</td><td>12.1</td><td>7.25</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>20.85</td><td>0.0</td><td>1.25</td></tr><tr><td>2</td><td>2023-01-01 00:10:29</td><td>2023-01-01 00:21:19</td><td>1</td><td>1.43</td><td>1</td><td>&quot;N&quot;</td><td>107</td><td>79</td><td>1</td><td>11.4</td><td>1.0</td><td>0.5</td><td>3.28</td><td>0.0</td><td>1.0</td><td>19.68</td><td>2.5</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 19)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ VendorID ┆ tpep_pick ┆ tpep_drop ┆ passenger ┆ … ┆ improveme ┆ total_amo ┆ congestio ┆ Airport_f │\n",
       "│ ---      ┆ up_dateti ┆ off_datet ┆ _count    ┆   ┆ nt_surcha ┆ unt       ┆ n_surchar ┆ ee        │\n",
       "│ i32      ┆ me        ┆ ime       ┆ ---       ┆   ┆ rge       ┆ ---       ┆ ge        ┆ ---       │\n",
       "│          ┆ ---       ┆ ---       ┆ i64       ┆   ┆ ---       ┆ f64       ┆ ---       ┆ f64       │\n",
       "│          ┆ datetime[ ┆ datetime[ ┆           ┆   ┆ f64       ┆           ┆ f64       ┆           │\n",
       "│          ┆ ns]       ┆ ns]       ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 2        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 1         ┆ … ┆ 1.0       ┆ 14.3      ┆ 2.5       ┆ 0.0       │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:32:10  ┆ 00:40:36  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 1         ┆ … ┆ 1.0       ┆ 16.9      ┆ 2.5       ┆ 0.0       │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:55:08  ┆ 01:01:27  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 1         ┆ … ┆ 1.0       ┆ 34.9      ┆ 2.5       ┆ 0.0       │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:25:04  ┆ 00:37:49  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 1        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 0         ┆ … ┆ 1.0       ┆ 20.85     ┆ 0.0       ┆ 1.25      │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:03:48  ┆ 00:13:25  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2        ┆ 2023-01-0 ┆ 2023-01-0 ┆ 1         ┆ … ┆ 1.0       ┆ 19.68     ┆ 2.5       ┆ 0.0       │\n",
       "│          ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│          ┆ 00:10:29  ┆ 00:21:19  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nyc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas de fechas a tipo DateTime en Polars\n",
    "df_nyc = df_nyc.with_columns(\n",
    "    pl.col('tpep_pickup_datetime').dt.date().alias('tpep_pickup_date'),\n",
    "    pl.col('tpep_dropoff_datetime').dt.date().alias('tpep_dropoff_date')\n",
    ")\n",
    "\n",
    "# Calcular la duración del viaje en segundos\n",
    "df_nyc = df_nyc.with_columns(\n",
    "    (pl.col('tpep_dropoff_datetime') - pl.col('tpep_pickup_datetime')).dt.total_seconds().alias('viaje_segundos')\n",
    ")\n",
    "# Eliminar las columnas originales de fecha y hora\n",
    "df_nyc = df_nyc.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>Airport_fee</th><th>tpep_pickup_date</th><th>tpep_dropoff_date</th><th>viaje_segundos</th></tr><tr><td>i32</td><td>i64</td><td>f64</td><td>i64</td><td>str</td><td>i32</td><td>i32</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>date</td><td>date</td><td>i64</td></tr></thead><tbody><tr><td>2</td><td>1</td><td>0.97</td><td>1</td><td>&quot;N&quot;</td><td>161</td><td>141</td><td>2</td><td>9.3</td><td>1.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>14.3</td><td>2.5</td><td>0.0</td><td>2023-01-01</td><td>2023-01-01</td><td>506</td></tr><tr><td>2</td><td>1</td><td>1.1</td><td>1</td><td>&quot;N&quot;</td><td>43</td><td>237</td><td>1</td><td>7.9</td><td>1.0</td><td>0.5</td><td>4.0</td><td>0.0</td><td>1.0</td><td>16.9</td><td>2.5</td><td>0.0</td><td>2023-01-01</td><td>2023-01-01</td><td>379</td></tr><tr><td>2</td><td>1</td><td>2.51</td><td>1</td><td>&quot;N&quot;</td><td>48</td><td>238</td><td>1</td><td>14.9</td><td>1.0</td><td>0.5</td><td>15.0</td><td>0.0</td><td>1.0</td><td>34.9</td><td>2.5</td><td>0.0</td><td>2023-01-01</td><td>2023-01-01</td><td>765</td></tr><tr><td>1</td><td>0</td><td>1.9</td><td>1</td><td>&quot;N&quot;</td><td>138</td><td>7</td><td>1</td><td>12.1</td><td>7.25</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>20.85</td><td>0.0</td><td>1.25</td><td>2023-01-01</td><td>2023-01-01</td><td>577</td></tr><tr><td>2</td><td>1</td><td>1.43</td><td>1</td><td>&quot;N&quot;</td><td>107</td><td>79</td><td>1</td><td>11.4</td><td>1.0</td><td>0.5</td><td>3.28</td><td>0.0</td><td>1.0</td><td>19.68</td><td>2.5</td><td>0.0</td><td>2023-01-01</td><td>2023-01-01</td><td>650</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 20)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ VendorID ┆ passenger ┆ trip_dist ┆ RatecodeI ┆ … ┆ Airport_f ┆ tpep_pick ┆ tpep_drop ┆ viaje_seg │\n",
       "│ ---      ┆ _count    ┆ ance      ┆ D         ┆   ┆ ee        ┆ up_date   ┆ off_date  ┆ undos     │\n",
       "│ i32      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│          ┆ i64       ┆ f64       ┆ i64       ┆   ┆ f64       ┆ date      ┆ date      ┆ i64       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 2        ┆ 1         ┆ 0.97      ┆ 1         ┆ … ┆ 0.0       ┆ 2023-01-0 ┆ 2023-01-0 ┆ 506       │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆ 1         ┆ 1         ┆           │\n",
       "│ 2        ┆ 1         ┆ 1.1       ┆ 1         ┆ … ┆ 0.0       ┆ 2023-01-0 ┆ 2023-01-0 ┆ 379       │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆ 1         ┆ 1         ┆           │\n",
       "│ 2        ┆ 1         ┆ 2.51      ┆ 1         ┆ … ┆ 0.0       ┆ 2023-01-0 ┆ 2023-01-0 ┆ 765       │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆ 1         ┆ 1         ┆           │\n",
       "│ 1        ┆ 0         ┆ 1.9       ┆ 1         ┆ … ┆ 1.25      ┆ 2023-01-0 ┆ 2023-01-0 ┆ 577       │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆ 1         ┆ 1         ┆           │\n",
       "│ 2        ┆ 1         ┆ 1.43      ┆ 1         ┆ … ┆ 0.0       ┆ 2023-01-0 ┆ 2023-01-0 ┆ 650       │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆ 1         ┆ 1         ┆           │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nyc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37000870, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nyc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las columnas originales de fecha y hora\n",
    "df_nyc = df_nyc.drop(['store_and_fwd_flag', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'airport_fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37000870, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nyc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el DataFrame de Polars a un objeto Arrow\n",
    "arrow_table = df_nyc.to_arrow()\n",
    "\n",
    "# Guardar el objeto Arrow en un archivo Arrow\n",
    "#pq.write_table(arrow_table, 'temperature.arrow')\n",
    "#pq.write_table(arrow_table, '../datasets/processed/df_yellow.arrow')\n",
    "pq.write_table(arrow_table, '../datasets/processed/df_yellow.arrow', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('VendorID', Int32),\n",
       "             ('passenger_count', Int64),\n",
       "             ('trip_distance', Float64),\n",
       "             ('RatecodeID', Int64),\n",
       "             ('store_and_fwd_flag', String),\n",
       "             ('PULocationID', Int32),\n",
       "             ('DOLocationID', Int32),\n",
       "             ('payment_type', Int64),\n",
       "             ('fare_amount', Float64),\n",
       "             ('extra', Float64),\n",
       "             ('mta_tax', Float64),\n",
       "             ('tip_amount', Float64),\n",
       "             ('tolls_amount', Float64),\n",
       "             ('improvement_surcharge', Float64),\n",
       "             ('total_amount', Float64),\n",
       "             ('congestion_surcharge', Float64),\n",
       "             ('Airport_fee', Float64),\n",
       "             ('tpep_pickup_date', Date),\n",
       "             ('tpep_dropoff_date', Date),\n",
       "             ('viaje_segundos', Int64)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_nyc.describe()\n",
    "df_nyc.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimo: -1694897908\n",
      "Maximo: 601751\n",
      "Media: 997.5984043618433\n",
      "Mediana: 752.0\n",
      "Desviación estándar: 278647.64816650894\n"
     ]
    }
   ],
   "source": [
    "# Calcular la media de la columna 'tviaje_segundos'\n",
    "mean_seconds = df_nyc['viaje_segundos'].mean()\n",
    "\n",
    "# Calcular la mediana de la columna 'tviaje_segundos'\n",
    "median_seconds = df_nyc['viaje_segundos'].median()\n",
    "\n",
    "# Calcular la desviación estándar de la columna 'tviaje_segundos'\n",
    "std_seconds = df_nyc['viaje_segundos'].std()\n",
    "\n",
    "# Obtener el valor mínimo de la columna 'viaje_segundos'\n",
    "min_seconds = df_nyc['viaje_segundos'].min()\n",
    "\n",
    "# Obtener el valor máximo de la columna 'viaje_segundos'\n",
    "max_seconds = df_nyc['viaje_segundos'].max()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Minimo:\", min_seconds)\n",
    "print(\"Maximo:\", max_seconds)\n",
    "print(\"Media:\", mean_seconds)\n",
    "print(\"Mediana:\", median_seconds)\n",
    "print(\"Desviación estándar:\", std_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros con valores negativos en 'viaje_segundos': 819\n"
     ]
    }
   ],
   "source": [
    "# Filtrar los registros con valores negativos en la columna 'viaje_segundos'\n",
    "negativos = df_nyc.filter(pl.col('viaje_segundos') < 0.0)\n",
    "\n",
    "# Obtener la cantidad de registros con valores negativos\n",
    "cantidad_negativos = negativos.height\n",
    "print(\"Cantidad de registros con valores negativos en 'viaje_segundos':\", cantidad_negativos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Eliminar los registros con valores negativos en la columna 'viaje_segundos'\n",
    "#df_nyc = df_nyc.drop(pl.col('viaje_segundos') < 0.0)\n",
    "# Filtrar las filas que cumplen la condición\n",
    "df_yellow = df_nyc.filter(pl.col('viaje_segundos') >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pl.scan_ipc(\"temperature.arrow\")\n",
    "# create a SQL context, registering the frame as a table\n",
    "#sql = pl.SQLContext(my_table=df)\n",
    "# create a SQL query to execute\n",
    "# Leer el archivo Arrow\n",
    "arrow_table = pq.read_table('../datasets/processed/temperature.arrow')\n",
    "\n",
    "# Convertir el objeto Arrow a un DataFrame de Polars\n",
    "df_polars = pl.from_arrow(arrow_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (17_520, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_date</th><th>temperature_2m</th></tr><tr><td>datetime[ns, UTC]</td><td>f32</td></tr></thead><tbody><tr><td>2022-01-01 00:00:00 UTC</td><td>8.346</td></tr><tr><td>2022-01-01 01:00:00 UTC</td><td>9.146</td></tr><tr><td>2022-01-01 02:00:00 UTC</td><td>7.996</td></tr><tr><td>2022-01-01 03:00:00 UTC</td><td>8.046</td></tr><tr><td>2022-01-01 04:00:00 UTC</td><td>7.646</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2023-12-31 19:00:00 UTC</td><td>6.396</td></tr><tr><td>2023-12-31 20:00:00 UTC</td><td>6.296</td></tr><tr><td>2023-12-31 21:00:00 UTC</td><td>5.796</td></tr><tr><td>2023-12-31 22:00:00 UTC</td><td>4.396</td></tr><tr><td>2023-12-31 23:00:00 UTC</td><td>3.446</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (17_520, 2)\n",
       "┌─────────────────────────┬────────────────┐\n",
       "│ event_date              ┆ temperature_2m │\n",
       "│ ---                     ┆ ---            │\n",
       "│ datetime[ns, UTC]       ┆ f32            │\n",
       "╞═════════════════════════╪════════════════╡\n",
       "│ 2022-01-01 00:00:00 UTC ┆ 8.346          │\n",
       "│ 2022-01-01 01:00:00 UTC ┆ 9.146          │\n",
       "│ 2022-01-01 02:00:00 UTC ┆ 7.996          │\n",
       "│ 2022-01-01 03:00:00 UTC ┆ 8.046          │\n",
       "│ 2022-01-01 04:00:00 UTC ┆ 7.646          │\n",
       "│ …                       ┆ …              │\n",
       "│ 2023-12-31 19:00:00 UTC ┆ 6.396          │\n",
       "│ 2023-12-31 20:00:00 UTC ┆ 6.296          │\n",
       "│ 2023-12-31 21:00:00 UTC ┆ 5.796          │\n",
       "│ 2023-12-31 22:00:00 UTC ┆ 4.396          │\n",
       "│ 2023-12-31 23:00:00 UTC ┆ 3.446          │\n",
       "└─────────────────────────┴────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "# Ejemplo de DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "# Convertir el DataFrame de Pandas a un DataFrame de Polars\n",
    "df_polars = pl.from_pandas(df)\n",
    "\n",
    "# Convertir el DataFrame de Polars a un objeto Arrow\n",
    "arrow_table = df_polars.to_arrow()\n",
    "\n",
    "# Guardar el objeto Arrow en un archivo Arrow\n",
    "pq.write_table(arrow_table, 'data.arrow')\n",
    "\n",
    "# Leer el archivo Arrow utilizando pl.scan_pyarrow_dataset()\n",
    "dset = ds.dataset(\"data.arrow\", format=\"ipc\")  \n",
    "df_loaded = (\n",
    "    pl.scan_pyarrow_dataset(dset)\n",
    "    .to_pandas()  # Convertir a DataFrame de Pandas para mostrarlo\n",
    ")\n",
    "\n",
    "# Mostrar el DataFrame cargado\n",
    "print(df_loaded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Leer el archivo Arrow\n",
    "arrow_table = pq.read_table('../datasets/processed/temperature.arrow')\n",
    "\n",
    "# Convertir el objeto Arrow a un DataFrame de Polars\n",
    "df_polars = pl.from_arrow(arrow_table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (17_520, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_date</th><th>temperature_2m</th></tr><tr><td>datetime[ns, UTC]</td><td>f32</td></tr></thead><tbody><tr><td>2022-01-01 00:00:00 UTC</td><td>8.346</td></tr><tr><td>2022-01-01 01:00:00 UTC</td><td>9.146</td></tr><tr><td>2022-01-01 02:00:00 UTC</td><td>7.996</td></tr><tr><td>2022-01-01 03:00:00 UTC</td><td>8.046</td></tr><tr><td>2022-01-01 04:00:00 UTC</td><td>7.646</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2023-12-31 19:00:00 UTC</td><td>6.396</td></tr><tr><td>2023-12-31 20:00:00 UTC</td><td>6.296</td></tr><tr><td>2023-12-31 21:00:00 UTC</td><td>5.796</td></tr><tr><td>2023-12-31 22:00:00 UTC</td><td>4.396</td></tr><tr><td>2023-12-31 23:00:00 UTC</td><td>3.446</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (17_520, 2)\n",
       "┌─────────────────────────┬────────────────┐\n",
       "│ event_date              ┆ temperature_2m │\n",
       "│ ---                     ┆ ---            │\n",
       "│ datetime[ns, UTC]       ┆ f32            │\n",
       "╞═════════════════════════╪════════════════╡\n",
       "│ 2022-01-01 00:00:00 UTC ┆ 8.346          │\n",
       "│ 2022-01-01 01:00:00 UTC ┆ 9.146          │\n",
       "│ 2022-01-01 02:00:00 UTC ┆ 7.996          │\n",
       "│ 2022-01-01 03:00:00 UTC ┆ 8.046          │\n",
       "│ 2022-01-01 04:00:00 UTC ┆ 7.646          │\n",
       "│ …                       ┆ …              │\n",
       "│ 2023-12-31 19:00:00 UTC ┆ 6.396          │\n",
       "│ 2023-12-31 20:00:00 UTC ┆ 6.296          │\n",
       "│ 2023-12-31 21:00:00 UTC ┆ 5.796          │\n",
       "│ 2023-12-31 22:00:00 UTC ┆ 4.396          │\n",
       "│ 2023-12-31 23:00:00 UTC ┆ 3.446          │\n",
       "└─────────────────────────┴────────────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    event_date  temperature_2m\n",
      "0    2022-01-01 00:00:00+00:00           8.346\n",
      "1    2022-01-01 01:00:00+00:00           9.146\n",
      "2    2022-01-01 02:00:00+00:00           7.996\n",
      "3    2022-01-01 03:00:00+00:00           8.046\n",
      "4    2022-01-01 04:00:00+00:00           7.646\n",
      "...                        ...             ...\n",
      "7169 2023-12-31 19:00:00+00:00           6.396\n",
      "7170 2023-12-31 20:00:00+00:00           6.296\n",
      "7171 2023-12-31 21:00:00+00:00           5.796\n",
      "7172 2023-12-31 22:00:00+00:00           4.396\n",
      "7173 2023-12-31 23:00:00+00:00           3.446\n",
      "\n",
      "[7174 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Crear un contexto SQL y registrar el DataFrame como una tabla\n",
    "sql = pl.SQLContext(frames={\"df_polars\": df_polars})\n",
    "\n",
    "result = sql.execute(\n",
    "    \"SELECT * FROM df_polars WHERE temperature_2m < 10\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Convertir el resultado a un DataFrame de Pandas para mostrarlo\n",
    "result_df = result.collect().to_pandas()\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
